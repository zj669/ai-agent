# çŸ¥è¯†åº“ç®¡ç† API - è®¾è®¡æ–‡æ¡£

## 1. èƒŒæ™¯ä¸ç›®æ ‡

### 1.1 ä¸šåŠ¡èƒŒæ™¯
**ç°çŠ¶é—®é¢˜**:
- ç³»ç»Ÿå·²å®ç° LTMï¼ˆé•¿æœŸè®°å¿†ï¼‰**è¯»å–**èƒ½åŠ›ï¼ˆ`VectorStore.search()`ï¼‰
- **ç¼ºå¤±**ï¼šçŸ¥è¯†åº“çš„å†™å…¥ã€ç®¡ç†ã€ç”Ÿå‘½å‘¨æœŸæ§åˆ¶
- **ç—›ç‚¹**ï¼šç”¨æˆ·æ— æ³•åŠ¨æ€æ›´æ–° Agent çš„çŸ¥è¯†åº“

**ä¸šåŠ¡ä»·å€¼**:
- è®©ç”¨æˆ·èƒ½å¤Ÿä¸Šä¼ äº§å“æ‰‹å†Œã€FAQã€æŠ€æœ¯æ–‡æ¡£ç­‰
- æ”¯æŒçŸ¥è¯†åº“çš„å¢åˆ æ”¹æŸ¥
- ä¸º Agent æä¾›åŠ¨æ€å¯æ‰©å±•çš„é•¿æœŸè®°å¿†

### 1.2 Ubiquitous Languageï¼ˆé€šç”¨è¯­è¨€ï¼‰
- **KnowledgeDatasetï¼ˆçŸ¥è¯†åº“ï¼‰**: ä¸€ä¸ªç‹¬ç«‹çš„çŸ¥è¯†é›†åˆï¼Œå¯¹åº” Milvus ä¸­çš„ä¸€ä¸ª Collection
- **KnowledgeDocumentï¼ˆçŸ¥è¯†æ–‡æ¡£ï¼‰**: ä¸Šä¼ çš„å•ä¸ªæ–‡ä»¶ï¼ˆPDF/Markdown/TXTï¼‰
- **DocumentChunkï¼ˆæ–‡æ¡£å—ï¼‰**: æ–‡æ¡£åˆ†å‰²åçš„ç‰‡æ®µï¼Œå¯¹åº”å‘é‡åº“ä¸­çš„ä¸€æ¡ Embedding
- **Embeddingï¼ˆå‘é‡åµŒå…¥ï¼‰**: æ–‡æœ¬å—çš„å‘é‡è¡¨ç¤º
- **DocumentParserï¼ˆæ–‡æ¡£è§£æå™¨ï¼‰**: å°†æ–‡ä»¶å†…å®¹æå–ä¸ºæ–‡æœ¬çš„ç»„ä»¶
- **ChunkingStrategyï¼ˆåˆ†å—ç­–ç•¥ï¼‰**: å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºåˆé€‚é•¿åº¦ç‰‡æ®µçš„ç­–ç•¥

---

## 2. é¢†åŸŸæ¨¡å‹ï¼ˆDDD æˆ˜æœ¯è®¾è®¡ï¼‰

### 2.1 èšåˆæ ¹ (Aggregate Root)

#### KnowledgeDataset (çŸ¥è¯†åº“èšåˆæ ¹)
**èŒè´£**: ç®¡ç†çŸ¥è¯†åº“çš„ç”Ÿå‘½å‘¨æœŸã€æ–‡æ¡£é›†åˆ

> **âš ï¸ æ¶æ„ä¼˜åŒ–**: ç§»é™¤ `collectionName` å­—æ®µã€‚é‡‡ç”¨ **å• Collection + Metadata è¿‡æ»¤** ç­–ç•¥ï¼Œæ‰€æœ‰ Agent çš„çŸ¥è¯†å­˜å‚¨åœ¨ç»Ÿä¸€çš„ `agent_knowledge_base` Collection ä¸­ï¼Œé€šè¿‡ `agentId` å’Œ `datasetId` åœ¨ Metadata ä¸­è¿›è¡Œéš”ç¦»ã€‚

```java
package com.zj.aiagent.domain.knowledge.entity;

public class KnowledgeDataset {
    // === æ ‡è¯† ===
    private String datasetId;  // èšåˆæ ¹ ID
    
    // === åŸºæœ¬ä¿¡æ¯ ===
    private String name;
    private String description;
    private Long userId;  // æ‰€æœ‰è€…
    private Long agentId;  // å¯é€‰ï¼šç»‘å®šçš„ Agent ID
    
    // === å‘é‡å­˜å‚¨æ˜ å°„ ===
    // ç§»é™¤ collectionNameï¼Œæ‰€æœ‰çŸ¥è¯†åº“å…±äº« "agent_knowledge_base" Collection
    // é€šè¿‡ Metadata { "agentId": xxx, "datasetId": xxx } è¿›è¡Œéš”ç¦»
    
    // === ç»Ÿè®¡ä¿¡æ¯ ===
    private Integer documentCount;
    private Integer totalChunks;
    
    // === å®¡è®¡å­—æ®µ ===
    private Instant createdAt;
    private Instant updatedAt;
    
    // === é¢†åŸŸè¡Œä¸º ===
    public void addDocument(KnowledgeDocument document) {
        this.documentCount++;
        this.updatedAt = Instant.now();
    }
    
    public void removeDocument(int chunkCount) {
        this.documentCount--;
        this.totalChunks -= chunkCount;
        this.updatedAt = Instant.now();
    }
    
    // æ–°å¢ï¼šè·å–å‘é‡æ£€ç´¢çš„ Metadata Filter
    public Map<String, Object> buildMetadataFilter() {
        Map<String, Object> filter = new HashMap<>();
        filter.put("datasetId", this.datasetId);
        if (this.agentId != null) {
            filter.put("agentId", this.agentId);
        }
        return filter;
    }
}
```

---

#### KnowledgeDocument (æ–‡æ¡£èšåˆæ ¹)
**èŒè´£**: ç®¡ç†å•ä¸ªæ–‡æ¡£çš„è§£æçŠ¶æ€ã€åˆ†å—è¿›åº¦ã€é”™è¯¯å¤„ç†

```java
package com.zj.aiagent.domain.knowledge.entity;

public class KnowledgeDocument {
    // === æ ‡è¯† ===
    private String documentId;
    private String datasetId;  // æ‰€å±çŸ¥è¯†åº“
    
    // === æ–‡ä»¶ä¿¡æ¯ ===
    private String filename;
    private String fileUrl;  // MinIO å­˜å‚¨è·¯å¾„
    private Long fileSize;
    private String contentType;  // application/pdf, text/markdown
    
    // === çŠ¶æ€ç®¡ç† ===
    private DocumentStatus status;  // PENDING, PROCESSING, COMPLETED, FAILED
    private Integer totalChunks;
    private Integer processedChunks;
    private String errorMessage;
    
    // === è§£æé…ç½® ===
    private ChunkingConfig chunkingConfig;
    
    // === å®¡è®¡å­—æ®µ ===
    private Instant uploadedAt;
    private Instant completedAt;
    
    // === é¢†åŸŸè¡Œä¸º ===
    public void startProcessing() {
        this.status = DocumentStatus.PROCESSING;
    }
    
    public void updateProgress(int processedChunks) {
        this.processedChunks = processedChunks;
    }
    
    public void markCompleted() {
        this.status = DocumentStatus.COMPLETED;
        this.completedAt = Instant.now();
    }
    
    public void markFailed(String errorMessage) {
        this.status = DocumentStatus.FAILED;
        this.errorMessage = errorMessage;
    }
}
```

---

### 2.2 å€¼å¯¹è±¡ (Value Object)

#### DocumentStatusï¼ˆæ–‡æ¡£çŠ¶æ€ï¼‰
```java
public enum DocumentStatus {
    PENDING,      // å·²ä¸Šä¼ ï¼Œç­‰å¾…å¤„ç†
    PROCESSING,   // æ­£åœ¨è§£æå‘é‡åŒ–
    COMPLETED,    // å®Œæˆ
    FAILED        // å¤±è´¥
}
```

#### ChunkingConfigï¼ˆåˆ†å—é…ç½®ï¼‰
```java
@Data
@Builder
public class ChunkingConfig {
    private Integer chunkSize;     // é»˜è®¤ 500
    private Integer chunkOverlap;  // é»˜è®¤ 50
    private ChunkingStrategy strategy;  // FIXED_LENGTH, SENTENCE
}
```

#### DocumentChunkï¼ˆæ–‡æ¡£å— - å€¼å¯¹è±¡ï¼‰
```java
@Data
@Builder
public class DocumentChunk {
    private String chunkId;
    private String content;
    private Integer sequenceNumber;  // åœ¨æ–‡æ¡£ä¸­çš„é¡ºåº
    private Map<String, Object> metadata;  // { "page": 12, "section": "å®šä»·" }
}
```

---

### 2.3 é¢†åŸŸæœåŠ¡ (Domain Service)

#### DocumentProcessingServiceï¼ˆæ–‡æ¡£å¤„ç†é¢†åŸŸæœåŠ¡ï¼‰
**èŒè´£**: åè°ƒæ–‡æ¡£è§£æã€åˆ†å—ã€å‘é‡åŒ–çš„å¤æ‚æµç¨‹

```java
public interface DocumentProcessingService {
    /**
     * å¤„ç†æ–‡æ¡£ï¼Œç”Ÿæˆå‘é‡å¹¶å­˜å‚¨
     */
    void processDocument(KnowledgeDocument document, InputStream fileStream);
}
```

#### KnowledgeRetrievalServiceï¼ˆçŸ¥è¯†æ£€ç´¢é¢†åŸŸæœåŠ¡ï¼‰
**èŒè´£**: ä¸º SchedulerService æä¾›é•¿æœŸè®°å¿†æ£€ç´¢èƒ½åŠ›ï¼Œè‡ªåŠ¨è¿‡æ»¤ Agent æƒé™

> **ğŸ”— ä¸ SchedulerService è”åŠ¨**: åœ¨å·¥ä½œæµå¯åŠ¨å‰ï¼ŒSchedulerService è°ƒç”¨æ­¤æœåŠ¡åŠ è½½ LTMã€‚

```java
public interface KnowledgeRetrievalService {
    /**
     * æ ¹æ® Agent ID å’ŒæŸ¥è¯¢æ£€ç´¢çŸ¥è¯†
     * 
     * @param agentId Agent IDï¼ˆç”¨äºæƒé™éš”ç¦»ï¼‰
     * @param query   ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
     * @param topK    è¿”å›ç»“æœæ•°é‡
     * @return ç›¸å…³çŸ¥è¯†ç‰‡æ®µ
     */
    List<String> retrieve(Long agentId, String query, int topK);
    
    /**
     * æ ¹æ® Dataset ID æ£€ç´¢ï¼ˆæµ‹è¯•ç”¨ï¼‰
     */
    List<String> retrieveByDataset(String datasetId, String query, int topK);
}
```

---

### 2.4 ä»“å‚¨æ¥å£ (Repository Port)

```java
public interface KnowledgeDatasetRepository {
    KnowledgeDataset save(KnowledgeDataset dataset);
    Optional<KnowledgeDataset> findById(String datasetId);
    List<KnowledgeDataset> findByUserId(Long userId);
    void deleteById(String datasetId);
}

public interface KnowledgeDocumentRepository {
    KnowledgeDocument save(KnowledgeDocument document);
    Optional<KnowledgeDocument> findById(String documentId);
    Page<KnowledgeDocument> findByDatasetId(String datasetId, Pageable pageable);
    void deleteById(String documentId);
}
```

---

### 2.5 åŸºç¡€è®¾æ–½æ¥å£ (Infrastructure Port)

#### FileStorageServiceï¼ˆæ–‡ä»¶å­˜å‚¨æœåŠ¡ï¼‰
```java
public interface FileStorageService {
    String upload(String bucketName, String objectName, InputStream inputStream, long size);
    InputStream download(String bucketName, String objectName);
    void delete(String bucketName, String objectName);
}
```

#### DocumentReaderAdapterï¼ˆæ–‡æ¡£è¯»å–é€‚é…å™¨ï¼‰
> **âœ… æ¶æ„ä¼˜åŒ–**: å¤ç”¨ **Spring AI** çš„ `DocumentReader` æŠ½è±¡ï¼Œè€Œéæ‰‹å†™è§£æå™¨ã€‚

```java
public interface DocumentReaderAdapter {
    /**
     * ä½¿ç”¨ Spring AI TikaDocumentReader è¯»å–æ–‡æ¡£
     * æ”¯æŒ PDF, DOCX, TXT, MD ç­‰å¤šç§æ ¼å¼
     */
    List<org.springframework.ai.document.Document> readDocuments(Resource resource);
}
```

#### TextSplitterAdapterï¼ˆæ–‡æœ¬åˆ†å—é€‚é…å™¨ï¼‰
> **âœ… æ¶æ„ä¼˜åŒ–**: å¤ç”¨ **Spring AI** çš„ `TokenTextSplitter`ï¼Œæ— éœ€æ‰‹å†™åˆ†å—é€»è¾‘ã€‚

```java
public interface TextSplitterAdapter {
    /**
     * ä½¿ç”¨ Spring AI TokenTextSplitter åˆ†å—
     */
    List<org.springframework.ai.document.Document> split(
        List<org.springframework.ai.document.Document> documents,
        int chunkSize,
        int overlap
    );
}
```

---

## 3. API æ¥å£è®¾è®¡

### 3.1 Controller å±‚

#### KnowledgeController
**è·¯å¾„**: `com.zj.aiagent.interfaces.knowledge.KnowledgeController`

**æ¥å£åˆ—è¡¨**:
| Method | Path | æè¿° |
|--------|------|------|
| POST | `/api/knowledge/dataset` | åˆ›å»ºçŸ¥è¯†åº“ |
| GET | `/api/knowledge/dataset/list` | æŸ¥è¯¢çŸ¥è¯†åº“åˆ—è¡¨ |
| DELETE | `/api/knowledge/dataset/{id}` | åˆ é™¤çŸ¥è¯†åº“ |
| POST | `/api/knowledge/document/upload` | ä¸Šä¼ æ–‡æ¡£ |
| GET | `/api/knowledge/document/list` | æ–‡æ¡£åˆ—è¡¨ |
| GET | `/api/knowledge/document/{id}` | æ–‡æ¡£è¯¦æƒ… |
| DELETE | `/api/knowledge/document/{id}` | åˆ é™¤æ–‡æ¡£ |
| POST | `/api/knowledge/search` | æµ‹è¯•æ£€ç´¢ |

---

## 4. äº¤äº’æ—¶åº

### 4.1 æ–‡æ¡£ä¸Šä¼ ä¸å‘é‡åŒ–æµç¨‹

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as KnowledgeController
    participant App as KnowledgeApplicationService
    participant MinIO as FileStorageService
    participant Async as AsyncDocumentProcessor
    participant Parser as DocumentParser
    participant Vector as VectorStore
    participant Repo as DocumentRepository

    User->>API: POST /document/upload (file, datasetId)
    API->>MinIO: ä¸Šä¼ æ–‡ä»¶åˆ° MinIO
    MinIO-->>API: è¿”å›æ–‡ä»¶ URL
    API->>Repo: ä¿å­˜ Document (status=PENDING)
    API-->>User: è¿”å› documentId
    
    API->>Async: è§¦å‘å¼‚æ­¥ä»»åŠ¡ @Async
    
    Async->>Repo: æ›´æ–°çŠ¶æ€ä¸º PROCESSING
    Async->>MinIO: ä¸‹è½½æ–‡ä»¶æµ
    Async->>Parser: è§£ææ–‡ä»¶å†…å®¹
    Parser-->>Async: è¿”å›æ–‡æœ¬å†…å®¹
    
    loop åˆ†å—å¤„ç†
        Async->>Async: æ–‡æœ¬åˆ†å— (ChunkingStrategy)
        Async->>Vector: ç”Ÿæˆ Embedding å¹¶å­˜å‚¨
        Async->>Repo: æ›´æ–°è¿›åº¦ (processedChunks++)
    end
    
    Async->>Repo: æ ‡è®° COMPLETED
    Async->>Vector: åˆ·æ–°å‘é‡ç´¢å¼•
```

---

### 4.2 åˆ é™¤æ–‡æ¡£æµç¨‹

```mermaid
sequenceDiagram
    participant User
    participant API as KnowledgeController
    participant App as KnowledgeApplicationService
    participant Repo as DocumentRepository
    participant Vector as VectorStore
    participant MinIO as FileStorageService

    User->>API: DELETE /document/{id}
    API->>App: deleteDocument(documentId)
    App->>Repo: findById(documentId)
    Repo-->>App: Document å®ä½“
    
    App->>Vector: æ ¹æ® documentId åˆ é™¤å‘é‡
    App->>MinIO: åˆ é™¤æ–‡ä»¶
    App->>Repo: åˆ é™¤ Document è®°å½•
    
    App-->>API: è¿”å›æˆåŠŸ
    API-->>User: { "success": true }
```

---

## 5. æŠ€æœ¯å†³ç­–

### 5.1 æ–‡ä»¶å­˜å‚¨ï¼šMinIO
**é€‰å‹åŸå› **:
- å¼€æºå¯¹è±¡å­˜å‚¨ï¼Œå…¼å®¹ AWS S3 API
- æ”¯æŒæœ¬åœ°éƒ¨ç½²ï¼Œé™ä½å¼€å‘æˆæœ¬
- Spring Boot é›†æˆç®€å•

**é…ç½®ç¤ºä¾‹**:
```yaml
minio:
  endpoint: http://localhost:9000
  access-key: minioadmin
  secret-key: minioadmin
  bucket-name: knowledge-files
```

### 5.2 å¼‚æ­¥å¤„ç†ï¼šSpring @Async
- æ–‡æ¡£è§£æå’Œå‘é‡åŒ–æ˜¯ **CPU å¯†é›†å‹** ä»»åŠ¡ï¼Œä½¿ç”¨å¼‚æ­¥é¿å…é˜»å¡ API è¯·æ±‚
- é…ç½®çº¿ç¨‹æ± ï¼š`@EnableAsync` + `TaskExecutor`

### 5.3 æ–‡æ¡£è§£æä¸åˆ†å—ï¼šSpring AI é›†æˆ
> **âœ… å…³é”®ä¼˜åŒ–**: ç›´æ¥å¤ç”¨ **Spring AI ETL** èƒ½åŠ›ï¼Œé¿å…é‡å¤é€ è½®å­ã€‚

**Spring AI æä¾›çš„èƒ½åŠ›**:
- **TikaDocumentReader**: åŸºäº Apache Tikaï¼Œå¼€ç®±å³ç”¨æ”¯æŒ PDF, DOCX, TXT, MD ç­‰ 20+ æ ¼å¼
- **TokenTextSplitter**: æ™ºèƒ½åˆ†å—ï¼Œæ”¯æŒ Token è®¡æ•°ã€é‡å ç­–ç•¥
- **Document æŠ½è±¡**: ç»Ÿä¸€çš„æ–‡æ¡£å¯¹è±¡ï¼ŒåŒ…å« `content` å’Œ `metadata`

**ä¾èµ–é…ç½®**:
```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-tika-document-reader</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-core</artifactId>
</dependency>
```

**å®ç°ç¤ºä¾‹**:
```java
// Infrastructure å±‚å°è£…
public class SpringAIDocumentReaderAdapter implements DocumentReaderAdapter {
    @Override
    public List<Document> readDocuments(Resource resource) {
        TikaDocumentReader reader = new TikaDocumentReader(resource);
        return reader.get(); // è‡ªåŠ¨æ£€æµ‹æ ¼å¼å¹¶è§£æ
    }
}

public class SpringAITextSplitterAdapter implements TextSplitterAdapter {
    @Override
    public List<Document> split(List<Document> documents, int chunkSize, int overlap) {
        TokenTextSplitter splitter = new TokenTextSplitter(chunkSize, overlap);
        return splitter.split(documents);
    }
}
```

### 5.4 å‘é‡æ£€ç´¢éš”ç¦»ç­–ç•¥
> **âœ… å…³é”®ä¼˜åŒ–**: é‡‡ç”¨ **å• Collection + Metadata è¿‡æ»¤** ç­–ç•¥ã€‚

**è®¾è®¡åŸåˆ™**:
- âŒ **ä¸æ¨è**: ä¸ºæ¯ä¸ª Dataset åˆ›å»ºç‹¬ç«‹ Collectionï¼ˆé¢‘ç¹åˆ›å»º/åˆ é™¤ Collection æ˜¯é‡æ“ä½œï¼‰
- âœ… **æ¨è**: æ‰€æœ‰ Agent çŸ¥è¯†å­˜å‚¨åœ¨ç»Ÿä¸€çš„ `agent_knowledge_base` Collection

**éš”ç¦»ç­–ç•¥**:
```java
// å­˜å‚¨æ—¶ï¼šåœ¨ Metadata ä¸­æ³¨å…¥ agentId å’Œ datasetId
Map<String, Object> metadata = new HashMap<>();
metadata.put("agentId", 1001L);
metadata.put("datasetId", "ds_abc");
metadata.put("documentId", "doc_456");
metadata.put("filename", "äº§å“æ‰‹å†Œ.pdf");
metadata.put("page", 12);

vectorStore.store(agentId, chunkContent, metadata);
```

```java
// æ£€ç´¢æ—¶ï¼šä½¿ç”¨ Metadata Filter
List<String> results = knowledgeRetrievalService.retrieve(
    agentId: 1001,
    query: "äº§å“ä»·æ ¼",
    topK: 5
);

// å†…éƒ¨å®ç°ä¼šæ„é€  Filterï¼šagentId == 1001
// å¦‚æœæŒ‡å®š datasetIdï¼Œåˆ™é¢å¤–è¿‡æ»¤ï¼šdatasetId == "ds_abc"
```

**ä¼˜åŠ¿**:
- âœ… é¿å…é¢‘ç¹åˆ›å»º/åˆ é™¤ Collection çš„æ€§èƒ½å¼€é”€
- âœ… ç®€åŒ– SchedulerService é›†æˆï¼ˆåªéœ€ä¼  agentIdï¼‰
- âœ… æ”¯æŒè·¨ Dataset çš„çŸ¥è¯†èåˆæ£€ç´¢

---

## 6. é£é™©è¯„ä¼°

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|---------|
| PDF è§£æå¤±è´¥ï¼ˆæ‰«æä»¶ï¼‰ | é«˜ | æ•è·å¼‚å¸¸ï¼Œæ ‡è®° FAILEDï¼Œè®°å½•è¯¦ç»†é”™è¯¯ |
| MinIO è¿æ¥å¤±è´¥ | é«˜ | é…ç½®é‡è¯•æœºåˆ¶ï¼Œå¥åº·æ£€æŸ¥ |
| å‘é‡åŒ–è€—æ—¶è¿‡é•¿ | ä¸­ | ä½¿ç”¨æ‰¹é‡å¤„ç†ï¼Œé™åˆ¶å¹¶å‘ä»»åŠ¡æ•° |
| æ–‡ä»¶ä¸Šä¼ è¶…å¤§ï¼ˆ>10MBï¼‰ | ä¸­ | å‰ç«¯éªŒè¯ + åç«¯æ–‡ä»¶å¤§å°æ ¡éªŒ |

---

## 7. éªŒæ”¶æ ‡å‡†

- [ ] **P0**: æ”¯æŒä¸Šä¼  PDF/Markdown/TXT æ–‡ä»¶è‡³ MinIO
- [ ] **P0**: æ–‡æ¡£è§£ææˆåŠŸåï¼Œå‘é‡å†™å…¥ Milvusï¼ˆé€šè¿‡ `VectorStore`ï¼‰
- [ ] **P0**: æ–‡æ¡£åˆ—è¡¨ API èƒ½æ˜¾ç¤ºè§£æè¿›åº¦ï¼ˆprocessedChunks/totalChunksï¼‰
- [ ] **P0**: åˆ é™¤æ–‡æ¡£åï¼ŒMinIO æ–‡ä»¶å’Œ Milvus å‘é‡åŒæ­¥åˆ é™¤
- [ ] **P0**: å¼‚æ­¥ä»»åŠ¡å¤±è´¥æ—¶ï¼ŒçŠ¶æ€æ ‡è®°ä¸º FAILED å¹¶è®°å½• errorMessage
- [ ] **P1**: æœç´¢ API èƒ½æ£€ç´¢åˆ°ä¸Šä¼ çš„å†…å®¹ï¼ˆtopK=5ï¼‰

---

## 8. åˆ†å±‚å®ç°è®¡åˆ’ï¼ˆé¢„è§ˆï¼‰

### Domain Layer
- `KnowledgeDataset` èšåˆæ ¹
- `KnowledgeDocument` èšåˆæ ¹
- `DocumentStatus` æšä¸¾
- `ChunkingConfig` å€¼å¯¹è±¡
- Repository æ¥å£

### Infrastructure Layer
- `MilvusVectorStoreImpl` (å·²æœ‰ï¼Œ**éœ€æ‰©å±•**: æ”¯æŒ Metadata Filter æŸ¥è¯¢)
- `MinIOFileStorageService` (æ–°å¢)
- ~~`PDFDocumentParser`~~ â†’ **æ”¹ä¸º**: `SpringAIDocumentReaderAdapter` (å¤ç”¨ Spring AI TikaDocumentReader)
- ~~`MarkdownParser`~~ â†’ **å·²åŒ…å«åœ¨** Spring AI Tika ä¸­
- `SpringAITextSplitterAdapter` (æ–°å¢ï¼Œå°è£… TokenTextSplitter)
- `MySQLKnowledgeDatasetRepository` (æ–°å¢)
- `MySQLKnowledgeDocumentRepository` (æ–°å¢)

### Application Layer
- `KnowledgeApplicationService` (çŸ¥è¯†åº“ CRUD)
- `AsyncDocumentProcessor` (@Async æ–‡æ¡£è§£æ)
- `KnowledgeRetrievalServiceImpl` (å®ç° Domain Serviceï¼Œä¾› SchedulerService è°ƒç”¨)

### Interface Layer
- `KnowledgeController`
- DTOs: `DatasetCreateRequest`, `DocumentUploadResponse`, etc.

---

> **â›” STOP POINT**: è®¾è®¡æ–‡æ¡£ç”Ÿæˆå®Œæ¯•ã€‚è¯·ç¡®è®¤è®¾è®¡æ˜¯å¦é€šè¿‡ï¼Ÿï¼ˆè¾“å…¥ 'é€šè¿‡' è¿›å…¥ä»»åŠ¡æ‹†è§£ï¼‰
